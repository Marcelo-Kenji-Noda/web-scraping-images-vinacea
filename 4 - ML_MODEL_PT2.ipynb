{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely.geometry\n",
    "from shapely.geometry import Point\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import glob\n",
    "import rasterio\n",
    "import os\n",
    "import shutil\n",
    "import pyimpute\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamos gerar os pontos de presença"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_feature_contain_property(feat, key, value) -> bool:\n",
    "    prop = dict(feat.properties.items())\n",
    "    if prop[key] == value:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def check_if_feature_property_is_in(feat, key, values: list)->bool:\n",
    "    prop = dict(feat.properties.items())\n",
    "    if prop[key] in values:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Params:\n",
    "- STATES = [\"RS\",\"SC\",\"PR\",\"SP\",\"MG\",\"ES\",\"RJ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATES = [\"RS\",\"SC\",\"PR\",\"SP\",\"MG\",\"ES\",\"RJ\"]\n",
    "#STATES = [\"RS\",\"SC\",\"PR\",\"SP\",\"MG\",\"ES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: IBGE:  bcim_2016_21_11_2018\n",
    "import json\n",
    "\n",
    "INFOS_UFS = gpd.read_file(\"assets/bcim_2016_21_11_2018.gpkg\", layer = 'lim_unidade_federacao_a')[['sigla','geometry']]\n",
    "INFOS_UFS.to_file(\"assets/UFS_JSON\", driver = \"GeoJSON\")\n",
    "with open(\"assets/UFS_JSON\") as geofile:\n",
    "    geojson_file = json.load(geofile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    geojson_file: dict\n",
    "        - type: str\n",
    "        - crs: dict\n",
    "        - features: list\n",
    "          - feat_obj: dict\n",
    "            - type: str\n",
    "            - properties: dict\n",
    "              - sigla: str\n",
    "            - geometry: dict\n",
    "              - type: str\n",
    "              - coordinates: list[int, int]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering states\n",
    "Queremos atualizar a lista features removendo aqueles em que a sigla não está na lista STATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brazil_states_filtered = [feat for feat in geojson_file['features'] if feat['properties']['sigla'] in STATES]\n",
    "updated_brazil_states_filtered = {'type':geojson_file['type'],'features':brazil_states_filtered}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: IBGE:  bcim_2016_21_11_2018\n",
    "import json\n",
    "\n",
    "INFOS_UFS = gpd.read_file(\"assets/bcim_2016_21_11_2018.gpkg\", layer = 'lim_unidade_federacao_a')[['sigla','geometry']]\n",
    "INFOS_UFS.to_file(\"assets/UFS_JSON\", driver = \"GeoJSON\")\n",
    "\n",
    "def generate_random_points(polygon, number):   \n",
    "    minx, miny, maxx, maxy = polygon.bounds\n",
    "    x = np.random.uniform( minx, maxx, number )\n",
    "    y = np.random.uniform( miny, maxy, number )\n",
    "    return x, y\n",
    "\n",
    "with open(\"assets/UFS_JSON\") as geofile:\n",
    "    geojson_file = json.load(geofile)\n",
    "INFOS_UFS = INFOS_UFS[INFOS_UFS['sigla'].isin(STATES)].reset_index()\n",
    "br_union_geo = INFOS_UFS['geometry'].unary_union\n",
    "\n",
    "gdf_poly = gpd.GeoDataFrame(index=[\"myPoly\"], geometry=[br_union_geo], crs = {'init': 'epsg:4326'},)\n",
    "\n",
    "x, y = generate_random_points(br_union_geo, 6_000)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['points'] = list(zip(x,y))\n",
    "df['points'] = df['points'].apply(Point)\n",
    "gdf_points = gpd.GeoDataFrame(df, geometry='points')\n",
    "Sjoin = gpd.tools.sjoin(gdf_points, gdf_poly, predicate=\"within\", how='left')\n",
    "\n",
    "# Keep points in \"myPoly\"\n",
    "absence = gdf_points[Sjoin.index_right=='myPoly']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/codeforgermany/click_that_hood/main/public/data/brazil-states.geojson'\n",
    "with request.urlopen(url) as f:\n",
    "    brazil_states = json.load(f)\n",
    "    \n",
    "brazil_states_filtered = [feat for feat in brazil_states['features'] if feat['properties']['sigla'] in STATES]\n",
    "updated_brazil_states_filtered = {'type':brazil_states['type'],'features':brazil_states_filtered}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geojson_file_filtered = [feat for feat in geojson_file['features'] if feat['properties']['sigla'] in STATES]\n",
    "#updated_geojson_file_filtered = {'type':geojson_file['type'],'features':geojson_file_filtered}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "fig = px.choropleth(\n",
    "        INFOS_UFS,\n",
    "        locations=\"sigla\",\n",
    "        scope='south america',\n",
    "        center={\"lat\": -16.95, \"lon\": -47.78},\n",
    "        geojson=updated_geojson_file_filtered,\n",
    "        featureidkey='properties.sigla', # add\n",
    "        color_continuous_scale=\"Redor\",\n",
    "        hover_data={\"sigla\": True}\n",
    ")\n",
    "fig.update_geos(fitbounds=\"geojson\", visible=False,framewidth=2, showframe=True)\n",
    "fig.update_layout(margin=dict(l=10, r=100, t=50, b=50))\n",
    "fig.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(\n",
    "        INFOS_UFS,\n",
    "        locations=\"sigla\",\n",
    "        scope='south america',\n",
    "        center={\"lat\": -16.95, \"lon\": -47.78},\n",
    "        geojson=updated_brazil_states_filtered,\n",
    "        featureidkey='properties.sigla', # add\n",
    "        color_continuous_scale=\"Redor\",\n",
    "        hover_data={\"sigla\": True}\n",
    ")\n",
    "fig.update_geos(fitbounds=\"geojson\", visible=False,framewidth=2, showframe=True)\n",
    "fig.update_layout(margin=dict(l=10, r=100, t=50, b=50))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_points(polygon, number):   \n",
    "    minx, miny, maxx, maxy = polygon.bounds\n",
    "    x = np.random.uniform( minx, maxx, number )\n",
    "    y = np.random.uniform( miny, maxy, number )\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_union_geo = INFOS_UFS['geometry'].unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_poly = gpd.GeoDataFrame(index=[\"myPoly\"], geometry=[br_union_geo], crs = {'init': 'epsg:4326'},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = generate_random_points(br_union_geo, 6_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['points'] = list(zip(x,y))\n",
    "df['points'] = df['points'].apply(Point)\n",
    "gdf_points = gpd.GeoDataFrame(df, geometry='points')\n",
    "Sjoin = gpd.tools.sjoin(gdf_points, gdf_poly, predicate=\"within\", how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sjoin = gpd.tools.sjoin(gdf_points, gdf_poly, predicate=\"within\", how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep points in \"myPoly\"\n",
    "absence = gdf_points[Sjoin.index_right=='myPoly']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absence['STATUS'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE_PATH = \"assets/gibf.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ocurrence species data -> OSD_df\n",
    "OSD_df = pd.read_parquet(OUTPUT_FILE_PATH)\n",
    "\n",
    "# Creating Geometry\n",
    "OSD_df['geometry'] = list(zip(OSD_df[\"decimalLongitude\"], OSD_df[\"decimalLatitude\"]))\n",
    "OSD_df['geometry'] = OSD_df[\"geometry\"].apply(Point)\n",
    "\n",
    "# Create the geodataframe\n",
    "OSD_geoframe = gpd.GeoDataFrame(\n",
    "    OSD_df,\n",
    "    crs = {'init': 'epsg:4326'},\n",
    "    geometry = OSD_df['geometry']\n",
    ")\n",
    "OSD_geoframe = OSD_geoframe.to_crs(\"EPSG:4326\")\n",
    "OSD_geoframe.reset_index(drop=True, inplace = True)\n",
    "\n",
    "coord_list = [(x,y) for x,y in zip(OSD_geoframe['geometry'].x , OSD_geoframe['geometry'].y)]\n",
    "\n",
    "OSD_geoframe['Year'] = OSD_geoframe.eventDate.dt.year\n",
    "OSD_df = pd.DataFrame(OSD_geoframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OSD_df = OSD_df.rename(columns={'geometry':'points'})\n",
    "OSD_df['STATUS'] = 1\n",
    "\n",
    "OSD_df = OSD_df[['points','STATUS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_absence = pd.concat([absence, OSD_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_absence['decimalLatitude'] = presence_absence['points'].y\n",
    "presence_absence['decimalLongitude'] = presence_absence['points'].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_list = [(x,y) for x,y in zip(presence_absence['points'].x , presence_absence['points'].y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(\n",
    "    presence_absence,\n",
    "    lat=\"decimalLatitude\",\n",
    "    lon=\"decimalLongitude\",\n",
    "    hover_name=\"STATUS\",\n",
    "    hover_data=[\"STATUS\"],\n",
    "    color_discrete_sequence=[\"fuchsia\"],\n",
    "    color=\"STATUS\",\n",
    "    zoom=3,\n",
    "    height=500,\n",
    "    opacity=1\n",
    ")\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_list = [(x,y) for x,y in zip(presence_absence['points'].x , presence_absence['points'].y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIF_FILES = \"assets/wc2.1_10m_tmax/*.tif\"\n",
    "\n",
    "raster_files = glob.glob(TIF_FILES)\n",
    "src = rasterio.open(raster_files[0])\n",
    "\n",
    "for f in raster_files:\n",
    "    src = rasterio.open(f)\n",
    "    presence_absence[Path(f).stem] = [x for x in src.sample(coord_list)]\n",
    "    presence_absence[Path(f).stem] = presence_absence[Path(f).stem].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_absence[['decimalLatitude','decimalLongitude','STATUS']].to_parquet(\"model/presence_absence.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web-scraping-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
